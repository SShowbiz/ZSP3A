<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description"
    content="Project page of the paper <Zero-Shot Learning for the Primitives of 3D Affordance in General Objects>"">
  <meta property=" og:title" content="Zero-Shot Learning for the Primitives of 3D Affordance in General Objects" />
  <meta property="og:description"
    content="We present a method to extract 3D affordances in general objects with self-supervised manner and represent it with out novel representation called primitive form of 3D affordances, which not only represent the physical interaction, but also captures implicit effects; orientation tendency, spatial relation." />
  <meta property="og:url" content="https://sshowbiz.github.io/ZSP3A/" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/teaser.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="Zero-Shot Learning for the Primitives of 3D Affordance in General Objects">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/teaser.png">
  <meta name="twitter:card" content="static/images/teaser.png">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Zero-Shot, Primitives, 3D Affordance">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Zero-Shot Learning for the Primitives of 3D Affordance in General Objects</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/css/bootstrap.min.css">
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="stylesheet" href="static/js/video-comparison.js">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script src="static/js/video-comparison.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Zero-Shot Learning for the Primitives of 3D Affordance in General
              Objects</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://www.sshowbiz.xyz/" target="_blank">Hyeonwoo Kim</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="https://jellyheadandrew.github.io/" target="_blank">Sookwan Han</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="https://yj7082126.github.io/" target="_blank">Patrick Kwon</a><sup>2</sup>,</span>
              </span>
              <span class="author-block">
                <a href="https://jhugestar.github.io/" target="_blank">Hanbyul Joo</a><sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Seoul National University,</span>
              <span class="author-block"><sup>2</sup>Naver Webtoon AI</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- TODO: PAPER PDF link (e.g., https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf) -->
                <span class="link-block">
                  <a href="https://sshowbiz.github.io/ZSP3A/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- TODO: Supplementary PDF link (e.g., static/pdfs/supplementary_material.pdf) -->
                <span class="link-block">
                  <a href="https://sshowbiz.github.io/ZSP3A/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/SShowbiz/ZSP3A" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!--TODO: ArXiv abstract Link (e.g., https://arxiv.org/abs/<ARXIV PAPER ID>)-->
                <span class="link-block">
                  <a href="https://sshowbiz.github.io/ZSP3A/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Teaser video-->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-image">
        <img src="static/images/teaser.png" alt="Random Image" id="tree" width="100%">
      </div>
    </div>
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h2 class="subtitle has-text-centered">
          We present a method to extract 3D affordance in general objects with zero-shot manner using our novel
          representation called <b>primitives of 3D affordances</b>, which not only represent
          physical
          interactions, but also captures implicit effects; orientational tendency, spatial relation.
        </h2>
      </div>
    </div>
  </section>
  <!-- End teaser video -->

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              One of the major challenges in AI is teaching machines to respond precisely and utilize environmental
              functionalities, thereby achieving affordance awareness that humans possess. Despite its importance, the
              field has been lagging in terms of learning, especially in 3D, as annotating affordance accompanies a
              laborious process due to the numerous variations of human-object interaction. The low availability of
              affordance data limits the learning in terms of generalization for object categories, and also simplifies
              the representation of affordance, capturing only a fraction of the entire affordance.
              To overcome these challenges, we propose a novel, self-supervised method to "generate" the 3D affordance
              examples given only a 3D object input, without any manual annotating procedures. The method starts by
              capturing the 3D object into images and creating 2D affordance examples by inserting humans into the image
              via inpainting diffusion models, where we present the Adaptive Mask algorithm to enable human insertion
              without altering the original details of the object.
              The method consequently lifts inserted humans back to 3D to create 3D human-object pairs, where the depth
              ambiguity is resolved within a depth optimization framework that utilizes pre-generated human postures
              from multiple viewpoints.
              We also provide a novel affordance representation defined on relative orientations and proximity between
              dense human and object points, that can be easily aggregated from any 3D HOI datasets. The proposed
              representation serves as a primitive that can be manifested to conventional affordance representations via
              simple transformations, ranging from physically exerted affordances (e.g., contact) to nonphysical ones
              (e.g., orientation tendency, spatial relations).
              We demonstrate the efficacy of our method and representation by generating the 3D affordance samples and
              deriving high-quality affordance examples from the representation, including contact, orientation, and
              spatial occupancies.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->


  <!-- Image carousel -->
  <!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item"> -->
  <!-- Your image here -->
  <!-- <img src="static/images/carousel1.jpg" alt="MY ALT TEXT" />
          <h2 class="subtitle has-text-centered">
            First image description.
          </h2>
        </div>
        <div class="item"> -->
  <!-- Your image here -->
  <!-- <img src="static/images/carousel2.jpg" alt="MY ALT TEXT" />
          <h2 class="subtitle has-text-centered">
            Second image description.
          </h2>
        </div>
        <div class="item"> -->
  <!-- Your image here -->
  <!-- <img src="static/images/carousel3.jpg" alt="MY ALT TEXT" />
          <h2 class="subtitle has-text-centered">
            Third image description.
          </h2>
        </div>
        <div class="item"> -->
  <!-- Your image here -->
  <!-- <img src="static/images/carousel4.jpg" alt="MY ALT TEXT" />
          <h2 class="subtitle has-text-centered">
            Fourth image description.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section> -->
  <!-- End image carousel -->

  <!-- Method -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container is-max-desktop">

        <h2 class="title is-3 has-text-centered">Method</h2>
        <img src="static/images/method.png" alt="Random Image" id="tree" height="100%">
        <h2 class="subtitle has-text-centered">
          Our method consists of two parts; <b>(1) Generating 3D affordance samples</b>, represented in <span
            style="color:#C62300">red</span> box, <b>(2) Learning primitive of 3D affordance</b>, represented in <span
            style="color:#298AE5">blue</span> box. We introduce Adaptive Mask Inpainting and Depth Optimization via
          Weak Auxiliary Cue for generating diverse and precise 3D affordance samples. From the generated samples, we
          learn the pointwise distribution of relative orientation and proximity, which can be derived into various
          forms of 3D affordance including contact, orientational tendency, and spatial relation.
        </h2>
      </div>
    </div>
  </section>



  <!-- Youtube video -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <!-- Paper video. -->
        <h2 class="title is-3 has-text-centered">Video Presentation</h2>
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">

            <div class="publication-video">
              <!-- Youtube embed code here -->
              <iframe src="https://www.youtube.com/embed/TmsemRskUe0" frameborder="0" allow="autoplay; encrypted-media"
                allowfullscreen></iframe>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End youtube video -->

  <!-- Video carousel -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3 has-text-centered">Generated 3D Affordance Samples</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <video poster="" id="suitcase" autoplay controls muted loop playsinline>
              <source src="./static/videos/samples/suitcase.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item">
            <video poster="" id="skateboard" autoplay controls muted loop playsinline>
              <source src="./static/videos/samples/skateboard.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item">
            <video poster="" id="keyboard" autoplay controls muted loop playsinline>\
              <source src="./static/videos/samples/keyboard.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item">
            <video poster="" id="chair" autoplay controls muted loop playsinline>\
              <source src="./static/videos/samples/chair.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item">
            <video poster="" id="tennis racket" autoplay controls muted loop playsinline>\
              <source src="./static/videos/samples/tennis_racket.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item">
            <video poster="" id="shovel" autoplay controls muted loop playsinline>\
              <source src="./static/videos/samples/shovel.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End video carousel -->

  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3 has-text-centered">Learned Primitives Represented with Contact</h2>


        <div class="row">
          <!-- MOTORCYCLE -->
          <div class="col">
            <div class="video-compare-container" style="width: 100%">
              <video class="video" width=100% id="motorcycle_human" loop playsinline autoplay muted
                src="./static/videos/contact/motorcycle_human.mp4" onplay="resizeAndPlay(this)"></video>
              <canvas class="videoMerge" id="motorcycle_humanMerge"></canvas>
            </div>
          </div>
          <div class="col">
            <div class="video-compare-container" style="width: 100%">
              <video class="video" width=100% id="motorcycle_object" loop playsinline autoplay muted
                src="./static/videos/contact/motorcycle_object.mp4" onplay="resizeAndPlay(this)"></video>
              <canvas height=0 class="videoMerge" id="motorcycle_objectMerge"></canvas>
            </div>
          </div>

          <!-- KEYBOARD -->
          <div class="col">
            <div class="video-compare-container" style="width: 100%">
              <video class="video" width=100% id="keyboard_human" loop playsinline autoplay muted
                src="./static/videos/contact/keyboard_human.mp4" onplay="resizeAndPlay(this)"></video>
              <canvas class="videoMerge" id="keyboard_humanMerge"></canvas>
            </div>
          </div>
          <div class="col">
            <div class="video-compare-container" style="width: 100%">
              <video class="video" width=100% id="keyboard_object" loop playsinline autoplay muted
                src="./static/videos/contact/keyboard_object.mp4" onplay="resizeAndPlay(this)"></video>
              <canvas class="videoMerge" id="keyboard_objectMerge"></canvas>
            </div>
          </div>


          <!-- SKATEBOARD -->
          <div class="col">
            <div class="video-compare-container" style="width: 100%">
              <video class="video" width=100% id="skateboard_human" loop playsinline autoplay muted
                src="./static/videos/contact/skateboard_human.mp4" onplay="resizeAndPlay(this)"></video>
              <canvas class="videoMerge" id="skateboard_humanMerge"></canvas>
            </div>
          </div>
          <div class="col">
            <div class="video-compare-container" style="width: 100%">
              <video class="video" width=100% id="skateboard_object" loop playsinline autoplay muted
                src="./static/videos/contact/skateboard_object.mp4" onplay="resizeAndPlay(this)"></video>
              <canvas class="videoMerge" id="skateboard_objectMerge"></canvas>
            </div>
          </div>

        </div>

        <div class="row">
          <!-- SOCCER BALL -->
          <div class="col">
            <div class="video-compare-container" style="width: 100%">
              <video class="video" width=100% id="soccer_human" loop playsinline autoplay muted
                src="./static/videos/contact/soccer_human.mp4" onplay="resizeAndPlay(this)"></video>
              <canvas class="videoMerge" id="soccer_humanMerge"></canvas>
            </div>
          </div>
          <div class="col">
            <div class="video-compare-container" style="width: 100%">
              <video class="video" width=100% id="soccer_object" loop playsinline autoplay muted
                src="./static/videos/contact/soccer_object.mp4" onplay="resizeAndPlay(this)"></video>
              <canvas height=0 class="videoMerge" id="soccer_objectMerge"></canvas>
            </div>
          </div>

          <!-- SUITCASE -->
          <div class="col">
            <div class="video-compare-container" style="width: 100%">
              <video class="video" width=100% id="suitcase_human" loop playsinline autoplay muted
                src="./static/videos/contact/suitcase_human.mp4" onplay="resizeAndPlay(this)"></video>
              <canvas class="videoMerge" id="suitcase_humanMerge"></canvas>
            </div>
          </div>
          <div class="col">
            <div class="video-compare-container" style="width: 100%">
              <video class="video" width=100% id="suitcase_object" loop playsinline autoplay muted
                src="./static/videos/contact/suitcase_object.mp4" onplay="resizeAndPlay(this)"></video>
              <canvas class="videoMerge" id="suitcase_objectMerge"></canvas>
            </div>
          </div>


          <!-- TENNIS -->
          <div class="col">
            <div class="video-compare-container" style="width: 100%">
              <video class="video" width=100% id="tennis_human" loop playsinline autoplay muted
                src="./static/videos/contact/tennis_human.mp4" onplay="resizeAndPlay(this)"></video>
              <canvas class="videoMerge" id="tennis_humanMerge"></canvas>
            </div>
          </div>
          <div class="col">
            <div class="video-compare-container" style="width: 100%">
              <video class="video" width=100% id="tennis_object" loop playsinline autoplay muted
                src="./static/videos/contact/tennis_object.mp4" onplay="resizeAndPlay(this)"></video>
              <canvas class="videoMerge" id="tennis_objectMerge"></canvas>
            </div>
          </div>

        </div>
      </div>
  </section>





  <!-- Paper poster -->
  <!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe src="static/pdfs/sample.pdf" width="100%" height="550">
      </iframe>

    </div>
  </div>
</section> -->
  <!--End paper poster -->


  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>Comming Soon!</code></pre>
    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the of this website, we just ask that you link back to this page in the footer.
              <br> This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>